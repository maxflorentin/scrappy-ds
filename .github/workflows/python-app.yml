name: scrapper

on:
  schedule:
    - cron: "*/7 * * * *"

permissions:
  contents: write

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v3
    - name: Set up Python 3.10
      uses: actions/setup-python@v3
      with:
        python-version: "3.10"
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install flake8 pytest
        if [ -f requirements.txt ]; then pip install -r requirements.txt; fi
    - name: Scrappy run
      id: script
      run: |
        python scrapper.py "${{ secrets.URL1 }}" ${{ secrets.PRICE }} > output.txt
        python scrapper.py "${{ secrets.URL2 }}" ${{ secrets.PRICE }} >> output.txt
    - name: Read output file
      id: read_file
      run: |
        echo "::set-output name=SCRAPPER_OUTPUT::$(cat output.txt)" >> $GITHUB_OUTPUT
    - name: Check if output has content
      id: check_content
      run: |
        if [[ -s output.txt ]]; then
          echo "has_content=true" >> $GITHUB_ENV
        else
          echo "has_content=false" >> $GITHUB_ENV
        fi
    - name: Send email
      uses: dawidd6/action-send-mail@v3
      if: env.has_content == 'true'
      with:
        server_address: smtp.gmail.com
        secure: true
        server_port: 465
        username: ${{ secrets.EMAIL_USERNAME }}
        password: ${{ secrets.EMAIL_PASSWORD }}
        subject: "Scraper Output"
        to: ${{ secrets.EMAIL_TO }}
        from: ${{ secrets.EMAIL_FROM }}
        body: |
          Here is the output of the scraper:

          "${{ env.GITHUB_ENV }}:"
